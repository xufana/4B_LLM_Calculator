{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cTM25Cja8dc"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Prompt Engineering\n",
        "\n",
        "First, and the most obvious option we have is to choose a small model and set a series of experiments on how a model can work just as \"out-of-the-box\"."
      ],
      "metadata": {
        "id": "TD4h4uM2lKtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MIN_TRANSFORMERS_VERSION = '4.25.1'\n",
        "\n",
        "# check transformers version\n",
        "assert transformers.__version__ >= MIN_TRANSFORMERS_VERSION, f'Please upgrade transformers to version {MIN_TRANSFORMERS_VERSION} or higher.'\n"
      ],
      "metadata": {
        "id": "kNprhQ54bAKQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"togethercomputer/RedPajama-INCITE-Instruct-3B-v1\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"togethercomputer/RedPajama-INCITE-Instruct-3B-v1\", torch_dtype=torch.float16)\n",
        "model = model.to('cuda:0')"
      ],
      "metadata": {
        "id": "J28RaI9QcQPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# infer\n",
        "prompt = \"Q: one plus three\\nA: four\\nQ: twenty plus forty two\\nA: sixty two\\nQ: twelve plus thirty three\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "input_length = inputs.input_ids.shape[1]\n",
        "outputs = model.generate(\n",
        "    **inputs, max_new_tokens=7, do_sample=True, temperature=0.7, top_p=0.7, top_k=50, return_dict_in_generate=True\n",
        ")\n",
        "token = outputs.sequences[0, input_length:]\n",
        "output_str = tokenizer.decode(token)\n",
        "print(output_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK0ZB_PJbPNw",
        "outputId": "ab46f340-c13f-471f-c0ac-2bb19d01673f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: fifty seven\n",
            "Q:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# infer\n",
        "prompt = \"Q: 1 plus 3\\nA: 4\\nQ: 20 plus 42\\nA: 62 \\nQ: 12 plus 33\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "input_length = inputs.input_ids.shape[1]\n",
        "outputs = model.generate(\n",
        "    **inputs, max_new_tokens=10, do_sample=True, temperature=0.7, top_p=0.7, top_k=50, return_dict_in_generate=True\n",
        ")\n",
        "token = outputs.sequences[0, input_length:]\n",
        "output_str = tokenizer.decode(token)\n",
        "print(output_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSIjxltkcR0k",
        "outputId": "b203d737-8fda-4653-c136-b9cbfba1626f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: 45\n",
            "Q: -1 plus 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Fine-Tuning"
      ],
      "metadata": {
        "id": "ToNbohSC7K6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Dataset generation"
      ],
      "metadata": {
        "id": "0q7XZBTR7N2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to generate about 304000 pairs of numbers and the result of their addition as well."
      ],
      "metadata": {
        "id": "VOeUTrCi804c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition up to 16 digits\n",
        "\n",
        "pairs = \\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(1,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(3,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(6,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(9,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(12,16) for j in range(i,16) for k in range(1000)] \n",
        "\n",
        "random.shuffle(pairs)\n",
        "\n",
        "print(\"Addition:\", len(pairs))\n",
        "\n",
        "data_add = []\n",
        "\n",
        "for num1, num2 in pairs:\n",
        "    \n",
        "    if random.random()<0.5:\n",
        "        num1, num2 = num2, num1 \n",
        "\n",
        "    answer = num1 + num2\n",
        "    \n",
        "    question = f\"{num1} + {num2}\" \n",
        "    output = f\"{num1} + {num2} = {answer}\"\n",
        "    \n",
        "    assert(output.split()[-1] == str(answer))\n",
        "    data_add.append({\"input\": question, \"output\": output, \"answer\": str(answer)})\n",
        "\n"
      ],
      "metadata": {
        "id": "ywl8XPRBdR2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are also going to generate 304000 pairs of numbers and the result of their subtraction, since as a human being I find these two operations as inverse operations, which means addition undoes subtraction and subtraction undoes addition. The human logic might not work well on LLM logic, but that is what we are here to try and test. We will train two different models with and without this part of dataset and compare their results."
      ],
      "metadata": {
        "id": "rEjzvuhs9K9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = \\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(1,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(3,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(6,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(9,16) for j in range(i,16) for k in range(1000)] +\\\n",
        "[(random.randint(10**(i-1), 10**i), random.randint(10**(j-1), 10**j)) for i in range(12,16) for j in range(i,16) for k in range(1000)] \n",
        "\n",
        "random.shuffle(pairs)\n",
        "\n",
        "print(\"Subtraction:\", len(pairs))\n",
        "\n",
        "data_sub = []\n",
        "\n",
        "for num1, num2 in pairs:\n",
        "    \n",
        "    if random.random()<0.5:\n",
        "        num1, num2 = num2, num1 \n",
        "\n",
        "    answer = num1 - num2\n",
        "    \n",
        "    question = f\"{num1} - {num2}\" \n",
        "    output = f\"{num1} - {num2} = {answer}\"\n",
        "\n",
        "    assert(output.split()[-1] == str(answer))\n",
        "    data_sub.append({\"input\": question, \"output\": output, \"answer\": str(answer)})\n",
        "\n",
        "\n",
        "# with open(\"dataset.json\", \"w\") as f:\n",
        "#     json.dump(data_sub, f, indent=4)"
      ],
      "metadata": {
        "id": "szzUBtPP-T48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate arithmetic data\n",
        "\n",
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(data_add + data_sub, f, indent=4)\n",
        "\n",
        "print(\"Total:\", len(data_add + data_sub))\n",
        "print(\"Arithmetic dataset generated!\")"
      ],
      "metadata": {
        "id": "osFE0CeL-fru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add natural language instruction to the generated arithmetic data using template\n",
        "\n",
        "template_name = \"./templates/goat.json\"\n",
        "dataset_name = \"dataset.json\"\n",
        "\n",
        "with open(template_name) as fp:\n",
        "    template = json.load(fp)\n",
        "\n",
        "with open(dataset_name,\"rb\") as test_file:\n",
        "    data_original = json.load(test_file)\n",
        "\n",
        "data_converted = []\n",
        "\n",
        "for instance in data_original:\n",
        "    \n",
        "    arithmetic = instance[\"input\"]\n",
        "    \n",
        "    output_dict = {}\n",
        "        \n",
        "    \n",
        "    # add noise to instruction so that the model is robust to diverse question formats \n",
        "    if random.random() < 0.05:\n",
        "        if \" + \" in arithmetic:\n",
        "            arithmetic = \"the sum of \" + arithmetic.replace(\"+\", \"and\")\n",
        "\n",
        "        if \" - \" in arithmetic:\n",
        "            arithmetic = \"the difference of \" + arithmetic.replace(\"-\", \"and\")\n",
        "\n",
        "        if \" * \" in arithmetic:\n",
        "            arithmetic = \"the product of \" + arithmetic.replace(\"*\", \"and\")\n",
        "\n",
        "        if \" / \" in arithmetic:\n",
        "            arithmetic = \"the quotient and remainder of \" + arithmetic.replace(\"/\", \"and\")\n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        arithmetic = arithmetic.replace(\"*\", \"x\")    \n",
        "\n",
        "    if random.random() < 0.1:\n",
        "        arithmetic = arithmetic.replace(\"+\", \"plus\").replace(\"-\", \"minus\")\n",
        "        arithmetic = arithmetic.replace(\" x \", \" times \").replace(\"*\", \"multiplied by\").replace(\"/\", \"divided by\")    \n",
        "\n",
        "    if random.random() < 0.5:\n",
        "        if \"+\" in arithmetic or \"-\" in arithmetic or \"*\" in arithmetic or \"/\" in arithmetic or \"x\" in arithmetic:\n",
        "            arithmetic = arithmetic.replace(\" \", \"\")        \n",
        "\n",
        "    num = random.randint(1,500)\n",
        "\n",
        "    instruction = template[str(num)].format(\n",
        "        input = arithmetic\n",
        "    )\n",
        "    \n",
        "    output_dict[\"instruction\"] = instruction\n",
        "    output_dict[\"input\"] = instance[\"input\"]\n",
        "    output_dict[\"output\"] = instance[\"output\"]\n",
        "    output_dict[\"answer\"] = instance[\"answer\"]\n",
        "    \n",
        "    data_converted.append(output_dict)\n",
        "\n",
        "print(\"Total:\", len(data_converted))\n",
        "\n",
        "with open(\"dataset.json\", \"w\") as f:\n",
        "    json.dump(data_converted, f, indent=4)\n",
        "\n",
        "print(\"Instructions added!\")"
      ],
      "metadata": {
        "id": "xKrsPgpP-k9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}